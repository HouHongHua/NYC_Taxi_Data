name: Data Pipeline CI/CD

on:
  push:
    branches:
      - main

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_DB: ${{ secrets.DB_NAME }}
          POSTGRES_USER: ${{ secrets.DB_USER }}
          POSTGRES_PASSWORD: ${{ secrets.DB_PASSWORD }}
        options: >-
          --health-cmd="pg_isready -d $$POSTGRES_DB -U $$POSTGRES_USER"
          --health-interval=10s
          --health-timeout=5s
          --health-retries=10 

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .

    - name: Wait for PostgreSQL service
      env:
        PGPASSWORD: ${{ secrets.DB_PASSWORD }}
      run: |
        echo "Waiting for Postgres service to be fully ready..."
        for i in $(seq 1 30); do
          if pg_isready -h postgres -p 5432 -d ${{ secrets.DB_NAME }} -U ${{ secrets.DB_USER }}; then
            echo "PostgreSQL is ready!"
            exit 0
          fi
          echo "Still waiting for Postgres service... (Attempt $i/30)"
          sleep 1
        done
        echo "Error: Postgres service did not become available."
        exit 1

    - name: Create database table
      env:
        PGPASSWORD: ${{ secrets.DB_PASSWORD }}
      run: |
        psql -h postgres -U ${{ secrets.DB_USER }} -d ${{ secrets.DB_NAME }} -f ${{ secrets.SQL_DIR }}/create_table.sql

    - name: Download data files
      run: |
        mkdir -p ${{ secrets.RAW_DATA_PATH }}
        mkdir -p ${{ secrets.PROCESSED_DATA_PATH }}
        echo 

    - name: Run data pipeline script
      env:
        DB_USER: ${{ secrets.DB_USER }}
        DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
        DB_HOST: postgres 
        DB_PORT: ${{ secrets.DB_PORT }}
        DB_NAME: ${{ secrets.DB_NAME }}
        DB_TABLE_NAME: ${{ secrets.DB_TABLE_NAME }}
        RAW_DATA_PATH: ${{ secrets.RAW_DATA_PATH }}
        PROCESSED_DATA_PATH: ${{ secrets.PROCESSED_DATA_PATH }}
        SQL_DIR: ${{ secrets.SQL_DIR }}
      run: |
        python src/data_pipeline.py

    - name: Verify data in database (optional)
      env:
        PGPASSWORD: ${{ secrets.DB_PASSWORD }}
      run: |
        psql -h postgres -U ${{ secrets.DB_USER }} -d ${{ secrets.DB_NAME }} -c "SELECT COUNT(*) FROM ${{ secrets.DB_TABLE_NAME }};"
        echo "Data import verification query executed."

    - name: Upload model artifact (optional)
      uses: actions/upload-artifact@v4
      with:
        name: green-taxi-tip-prediction-model
        path: green_taxi_tip_prediction_model.joblib
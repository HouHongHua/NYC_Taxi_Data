name: Data Pipeline CI/CD

on:
  push:
    branches:
      - main

jobs:
  build_and_run:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_DB: ${{ secrets.DB_NAME }}
          POSTGRES_USER: ${{ secrets.DB_USER }}
          POSTGRES_PASSWORD: ${{ secrets.DB_PASSWORD }}
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .

    - name: Wait for PostgreSQL service
      run: |
        for i in `seq 1 10`; do
          nc -z localhost 5432 && break
          echo "Waiting for Postgres service..."
          sleep 5
        done
        nc -z localhost 5432
        echo "Postgres service is ready!"

    - name: Create database table
      env:
        PGPASSWORD: ${{ secrets.DB_PASSWORD }}
      run: |
        psql -h localhost -U ${{ secrets.DB_USER }} -d ${{ secrets.DB_NAME }} -f ${{ secrets.SQL_DIR }}/create_table.sql

    - name: Download data files 
      run: |
        mkdir -p ${{ secrets.RAW_DATA_PATH }}
        mkdir -p ${{ secrets.PROCESSED_DATA_PATH }}

        echo "--- 請注意 ---"
        echo "您需要在此處添加實際的數據下載命令，"
        echo "例如從雲端儲存下載您的 green_tripdata_2025-01.parquet 等檔案到 '${{ secrets.RAW_DATA_PATH }}'。"
        echo "如果您的數據檔案已經提交到 Git (不建議大檔案)，則此步驟可能不需要額外的下載命令。"
        echo "例如：使用 wget 或 curl 下載公有數據，或使用雲端CLI下載私有數據。"
        echo "--- 範例下載命令 (如果您的數據是公開的或可以透過 URL 下載) ---"
        echo "wget -P ${{ secrets.RAW_DATA_PATH }} https://www.nyc.gov/html/tlc/downloads/parquet/green_tripdata_2025-01.parquet"
        echo "wget -P ${{ secrets.RAW_DATA_PATH }} https://www.nyc.gov/html/tlc/downloads/parquet/green_tripdata_2025-02.parquet"
        echo "wget -P ${{ secrets.RAW_DATA_PATH }} https://www.nyc.gov/html/tlc/downloads/parquet/green_tripdata_2025-03.parquet"
        echo "-------------------"

    - name: Run data pipeline script
      env:
        DB_USER: ${{ secrets.DB_USER }}
        DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
        DB_HOST: postgres
        DB_PORT: ${{ secrets.DB_PORT }}
        DB_NAME: ${{ secrets.DB_NAME }}
        DB_TABLE_NAME: ${{ secrets.DB_TABLE_NAME }}
        RAW_DATA_PATH: ${{ secrets.RAW_DATA_PATH }}
        PROCESSED_DATA_PATH: ${{ secrets.PROCESSED_DATA_PATH }}
        SQL_DIR: ${{ secrets.SQL_DIR }}
      run: |
        python src/data_pipeline.py

    - name: Verify data in database (optional)
      env:
        PGPASSWORD: ${{ secrets.DB_PASSWORD }}
      run: |
        psql -h localhost -U ${{ secrets.DB_USER }} -d ${{ secrets.DB_NAME }} -c "SELECT COUNT(*) FROM ${{ secrets.DB_TABLE_NAME }};"
        echo "Data import verification query executed."

    - name: Upload model artifact (optional)
      uses: actions/upload-artifact@v4
      with:
        name: green-taxi-tip-prediction-model
        path: green_taxi_tip_prediction_model.joblib
        # path: ${{ secrets.PROCESSED_DATA_PATH }}/green_taxi_tip_prediction_model.joblib # If model is in PROCESSED_DATA_PATH